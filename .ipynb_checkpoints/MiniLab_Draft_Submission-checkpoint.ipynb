{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datamining 7331 Minilab: Analysis of Airbnb data using Logistic Regression and SVM\n",
    "\n",
    "By: William Arnost, Stephen Johnson, Sean Kennedy, Tazeb Abera\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we will be predicting the room type feature from the Airbnb data set using Logistic Regression and Support Vector Machines. Room type can take 3 values: 'Private room', 'Entire home/apt', and 'Shared room'. Room type by itself might not be a useful thing to predict, but we are hoping this can teach us something about our data for a future price prediction exercise. We will compare accuracy between the two algorithms, as well as look at hyperparameter tuning for each one. Then we discuss which model was more useful and look at the interpretation of the features. \n",
    "\n",
    "---\n",
    "## Contents\n",
    "\n",
    "* <a href=\"#DataPreperation\">Data Preperation</a>\n",
    "* <a href=\"#CreateModels\">Create Models</a>\n",
    "* <a href=\"#ModelAdvantages\">Model Advantages</a>\n",
    "* <a href=\"#InterpretFeatureImportance\">Interpret Feature Importance</a>\n",
    "* <a href=\"#InterpretSupportVectors\">Interpret Support Vectors</a>\n",
    "* <a href=\"#Conclusion\">Conclusion</a>\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "<a id=\"Loading\"></a>\n",
    "<a href=\"#top\">Back to Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"DataPreperation\"></a>\n",
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is where we load and prepare our data. This was not part of the grading rubric so we do not present any modeling or analysis here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "#sns.set(style=\"ticks\", color_codes=True)\n",
    "# sklearn stuff\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#yellobrick stuff\n",
    "from yellowbrick.classifier import ConfusionMatrix, DiscriminationThreshold, PrecisionRecallCurve, ClassificationReport, ClassPredictionError, ROCAUC\n",
    "from yellowbrick.target import ClassBalance\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions for model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_classifier(model,\n",
    "                       X_train,\n",
    "                       X_test,\n",
    "                       y_train,\n",
    "                       y_test,\n",
    "                       response='Response',\n",
    "                       classes=[0, 1, 2]):\n",
    "    matrix = ConfusionMatrix(model, classes=classes)\n",
    "    matrix.fit(X_train, y_train[response])\n",
    "    matrix.score(X_test, y_test[response])\n",
    "    matrix.show()\n",
    "    class_report = ClassificationReport(model, classes=classes, support=True)\n",
    "    class_report.fit(X_train, y_train[response])\n",
    "    class_report.score(X_test, y_test[response])\n",
    "    class_report.show()\n",
    "    roc_auc = ROCAUC(model, classes=classes)\n",
    "    roc_auc.fit(X_train, y_train[response])\n",
    "    roc_auc.score(X_test, y_test[response])\n",
    "    roc_auc.show()\n",
    "    recall = PrecisionRecallCurve(model)\n",
    "    recall.fit(X_train, y_train)\n",
    "    recall.score(X_test, y_test)\n",
    "    recall.show()\n",
    "    if len(classes) == 2:\n",
    "        disc_thresh = DiscriminationThreshold(model)\n",
    "        disc_thresh.fit(X_train, y_train.values.ravel())\n",
    "        disc_thresh.show()\n",
    "        return disc_thresh.thresholds_, disc_thresh.cv_scores_\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def sklearn_vif(exogs, data):\n",
    "\n",
    "    # initialize dictionaries\n",
    "    vif_dict, tolerance_dict = {}, {}\n",
    "\n",
    "    # form input data for each exogenous variable\n",
    "    for exog in exogs:\n",
    "        #print(exog)\n",
    "        not_exog = [i for i in exogs if i != exog]\n",
    "        #print(not_exog)\n",
    "        X, y = data[not_exog], data[exog]\n",
    "\n",
    "        # extract r-squared from the fit\n",
    "        r_squared = LinearRegression().fit(X, y).score(X, y)\n",
    "\n",
    "        # calculate VIF\n",
    "        vif = 1 / (1 - r_squared)\n",
    "        vif_dict[exog] = vif\n",
    "\n",
    "        # calculate tolerance\n",
    "        tolerance = 1 - r_squared\n",
    "        tolerance_dict[exog] = tolerance\n",
    "\n",
    "    # return VIF DataFrame\n",
    "    df_vif = pd.DataFrame({'VIF': vif_dict, 'Tolerance': tolerance_dict})\n",
    "\n",
    "    return df_vif\n",
    "\n",
    "\n",
    "def compute_new_conf_matrix(predictions, probabilities, cutoff, y_test):\n",
    "    #create a df of predictions and probabilities\n",
    "    predictions = pd.DataFrame(list(predictions), columns=['Predict'])\n",
    "    predicted_probs = pd.concat([\n",
    "        pd.DataFrame(list(probabilities), columns=['ProbFalse', 'ProbTrue']),\n",
    "        predictions\n",
    "    ],\n",
    "                                axis=1)\n",
    "    #make array of values where val > cutoff\n",
    "    predicted_probs['NewPredict'] = predicted_probs['ProbTrue'].apply(\n",
    "        lambda x: 1 if x >= cutoff else 0)\n",
    "    matrix = pd.DataFrame(confusion_matrix(y_test, predicted_probs.NewPredict))\n",
    "    matrix.rename(columns={\n",
    "        0: 'No_Predicted',\n",
    "        1: 'Yes_Predicted'\n",
    "    },\n",
    "                  index={\n",
    "                      0: 'No_True',\n",
    "                      1: 'Yes_True'\n",
    "                  },\n",
    "                  inplace=True)\n",
    "    return round(accuracy_score(y_test, predicted_probs.NewPredict),\n",
    "                 5), matrix, predicted_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 48895, 'name': 47897, 'host_id': 37457, 'host_name': 11453, 'neighbourhood_group': 5, 'neighbourhood': 221, 'latitude': 19048, 'longitude': 14718, 'room_type': 3, 'price': 674, 'minimum_nights': 109, 'number_of_reviews': 394, 'last_review': 1765, 'reviews_per_month': 938, 'calculated_host_listings_count': 47, 'availability_365': 366, 'ZIP': 199, 'dist_subway': 46157, 'cnt_all': 133, 'cnt_entire_home': 95, 'cnt_private_room': 74, 'cnt_shared_room': 14, 'avgprice_all': 1912, 'avgprice_entire_home': 1409, 'avgprice_private_room': 1309, 'avgprice_shared_room': 219}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>host_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>dist_subway</th>\n",
       "      <th>cnt_all</th>\n",
       "      <th>cnt_entire_home</th>\n",
       "      <th>cnt_private_room</th>\n",
       "      <th>cnt_shared_room</th>\n",
       "      <th>avgprice_all</th>\n",
       "      <th>avgprice_entire_home</th>\n",
       "      <th>avgprice_private_room</th>\n",
       "      <th>avgprice_shared_room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.889500e+04</td>\n",
       "      <td>4.889500e+04</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>38843.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48871.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "      <td>48895.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.901714e+07</td>\n",
       "      <td>6.762001e+07</td>\n",
       "      <td>40.728949</td>\n",
       "      <td>-73.952170</td>\n",
       "      <td>152.720687</td>\n",
       "      <td>7.029962</td>\n",
       "      <td>23.274466</td>\n",
       "      <td>1.373221</td>\n",
       "      <td>7.143982</td>\n",
       "      <td>112.781327</td>\n",
       "      <td>10675.111211</td>\n",
       "      <td>0.245997</td>\n",
       "      <td>52.815768</td>\n",
       "      <td>29.719726</td>\n",
       "      <td>22.013396</td>\n",
       "      <td>1.082646</td>\n",
       "      <td>152.703409</td>\n",
       "      <td>191.493067</td>\n",
       "      <td>98.024409</td>\n",
       "      <td>40.581520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.098311e+07</td>\n",
       "      <td>7.861097e+07</td>\n",
       "      <td>0.054530</td>\n",
       "      <td>0.046157</td>\n",
       "      <td>240.154170</td>\n",
       "      <td>20.510550</td>\n",
       "      <td>44.550582</td>\n",
       "      <td>1.680442</td>\n",
       "      <td>32.952519</td>\n",
       "      <td>131.622289</td>\n",
       "      <td>599.591915</td>\n",
       "      <td>0.346640</td>\n",
       "      <td>43.303548</td>\n",
       "      <td>29.254144</td>\n",
       "      <td>18.668278</td>\n",
       "      <td>2.615105</td>\n",
       "      <td>90.678742</td>\n",
       "      <td>114.468382</td>\n",
       "      <td>73.981026</td>\n",
       "      <td>93.479089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.539000e+03</td>\n",
       "      <td>2.438000e+03</td>\n",
       "      <td>40.499790</td>\n",
       "      <td>-74.244420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10001.000000</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.471945e+06</td>\n",
       "      <td>7.822033e+06</td>\n",
       "      <td>40.690100</td>\n",
       "      <td>-73.983070</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10024.000000</td>\n",
       "      <td>0.103457</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.812500</td>\n",
       "      <td>137.250000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.967728e+07</td>\n",
       "      <td>3.079382e+07</td>\n",
       "      <td>40.723070</td>\n",
       "      <td>-73.955680</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>11104.000000</td>\n",
       "      <td>0.173022</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>135.208333</td>\n",
       "      <td>180.850000</td>\n",
       "      <td>83.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.915218e+07</td>\n",
       "      <td>1.074344e+08</td>\n",
       "      <td>40.763115</td>\n",
       "      <td>-73.936275</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>11221.000000</td>\n",
       "      <td>0.269066</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>231.264463</td>\n",
       "      <td>111.500000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.648724e+07</td>\n",
       "      <td>2.743213e+08</td>\n",
       "      <td>40.913060</td>\n",
       "      <td>-73.712990</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>11697.000000</td>\n",
       "      <td>4.931115</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       host_id      latitude     longitude         price  \\\n",
       "count  4.889500e+04  4.889500e+04  48895.000000  48895.000000  48895.000000   \n",
       "mean   1.901714e+07  6.762001e+07     40.728949    -73.952170    152.720687   \n",
       "std    1.098311e+07  7.861097e+07      0.054530      0.046157    240.154170   \n",
       "min    2.539000e+03  2.438000e+03     40.499790    -74.244420      0.000000   \n",
       "25%    9.471945e+06  7.822033e+06     40.690100    -73.983070     69.000000   \n",
       "50%    1.967728e+07  3.079382e+07     40.723070    -73.955680    106.000000   \n",
       "75%    2.915218e+07  1.074344e+08     40.763115    -73.936275    175.000000   \n",
       "max    3.648724e+07  2.743213e+08     40.913060    -73.712990  10000.000000   \n",
       "\n",
       "       minimum_nights  number_of_reviews  reviews_per_month  \\\n",
       "count    48895.000000       48895.000000       38843.000000   \n",
       "mean         7.029962          23.274466           1.373221   \n",
       "std         20.510550          44.550582           1.680442   \n",
       "min          1.000000           0.000000           0.010000   \n",
       "25%          1.000000           1.000000           0.190000   \n",
       "50%          3.000000           5.000000           0.720000   \n",
       "75%          5.000000          24.000000           2.020000   \n",
       "max       1250.000000         629.000000          58.500000   \n",
       "\n",
       "       calculated_host_listings_count  availability_365           ZIP  \\\n",
       "count                    48895.000000      48895.000000  48871.000000   \n",
       "mean                         7.143982        112.781327  10675.111211   \n",
       "std                         32.952519        131.622289    599.591915   \n",
       "min                          1.000000          0.000000  10001.000000   \n",
       "25%                          1.000000          0.000000  10024.000000   \n",
       "50%                          1.000000         45.000000  11104.000000   \n",
       "75%                          2.000000        227.000000  11221.000000   \n",
       "max                        327.000000        365.000000  11697.000000   \n",
       "\n",
       "        dist_subway       cnt_all  cnt_entire_home  cnt_private_room  \\\n",
       "count  48895.000000  48895.000000     48895.000000      48895.000000   \n",
       "mean       0.245997     52.815768        29.719726         22.013396   \n",
       "std        0.346640     43.303548        29.254144         18.668278   \n",
       "min        0.000553      0.000000         0.000000          0.000000   \n",
       "25%        0.103457     20.000000         8.000000          7.000000   \n",
       "50%        0.173022     43.000000        20.000000         17.000000   \n",
       "75%        0.269066     73.000000        42.000000         33.000000   \n",
       "max        4.931115    230.000000       142.000000         91.000000   \n",
       "\n",
       "       cnt_shared_room  avgprice_all  avgprice_entire_home  \\\n",
       "count     48895.000000  48895.000000          48895.000000   \n",
       "mean          1.082646    152.703409            191.493067   \n",
       "std           2.615105     90.678742            114.468382   \n",
       "min           0.000000      0.000000              0.000000   \n",
       "25%           0.000000     94.812500            137.250000   \n",
       "50%           0.000000    135.208333            180.850000   \n",
       "75%           1.000000    189.000000            231.264463   \n",
       "max          26.000000   5000.000000           5000.000000   \n",
       "\n",
       "       avgprice_private_room  avgprice_shared_room  \n",
       "count           48895.000000          48895.000000  \n",
       "mean               98.024409             40.581520  \n",
       "std                73.981026             93.479089  \n",
       "min                 0.000000              0.000000  \n",
       "25%                64.500000              0.000000  \n",
       "50%                83.666667              0.000000  \n",
       "75%               111.500000             60.000000  \n",
       "max              3000.000000           1800.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ABNB_NY_V2.csv')\n",
    "summary = data.describe()\n",
    "print({x: len(data[x].unique()) for x in data.columns})\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['price'] = data['price'].astype('float')\n",
    "data['minimum_nights'] = data['minimum_nights'].astype('float')\n",
    "data['number_of_reviews'] = data['number_of_reviews'].astype('float')\n",
    "data['calculated_host_listings_count'] = data[\n",
    "    'calculated_host_listings_count'].astype('float')\n",
    "data['availability_365'] = data['availability_365'].astype('float')\n",
    "data['dist_subway'] = data['dist_subway'].astype('float')\n",
    "data['cnt_all'] = data['cnt_all'].astype('float')\n",
    "data['cnt_all'] = data['cnt_all'].astype('float')\n",
    "data['cnt_entire_home'] = data['cnt_entire_home'].astype('float')\n",
    "data['cnt_private_room'] = data['cnt_private_room'].astype('float')\n",
    "data['cnt_shared_room'] = data['cnt_shared_room'].astype('float')\n",
    "data['avgprice_all'] = data['avgprice_all'].astype('float')\n",
    "data['avgprice_entire_home'] = data['avgprice_entire_home'].astype('float')\n",
    "data['avgprice_private_room'] = data['avgprice_private_room'].astype('float')\n",
    "data['avgprice_shared_room'] = data['avgprice_shared_room'].astype('float')\n",
    "data['neighbourhood_group'] = data['neighbourhood_group'].astype('category')\n",
    "data['neighbourhood'] = data['neighbourhood'].astype('category')\n",
    "data['ZIP'] = data['ZIP'].astype('category')\n",
    "data['last_review'] = pd.to_datetime(data['last_review'])\n",
    "\n",
    "data['days_since_last_review'] = (\n",
    "    dt.datetime.strptime('2020-01-01', '%Y-%m-%d') -\n",
    "    data['last_review']).dt.days\n",
    "data.days_since_last_review.fillna(data.days_since_last_review.max(),\n",
    "                                   inplace=True)\n",
    "data.drop(columns=['last_review'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.price != 0].copy()\n",
    "data = data[data.price < 300].copy()\n",
    "data = data[data.minimum_nights <= 20].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'room_type'\n",
    "room_types = {'Entire home/apt': 0, 'Private room': 1, 'Shared room': 2}\n",
    "data['Response'] = data.apply(lambda x: room_types[x.room_type], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Columns that won't be used in modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\n",
    "    columns=['id', 'name', 'host_id', 'host_name', 'neighbourhood', 'ZIP'],\n",
    "    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature / Target Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40180, 20), (40180, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final = data\n",
    "features, target = data_final.drop(\n",
    "    columns=['Response']), data_final.loc[:, ['Response']]\n",
    "features.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"CreateModels\"></a>\n",
    "# Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[50] Create a logistic regression model and a support vector machine model for the classification task involved with your dataset. Assess how well each model performs (use 80/20 training/testing split for your data). Adjust parameters of the models to make them more accurate. If your dataset size requires the use of stochastic gradient descent, then linear kernel only is fine to use. That is, the SGDClassifier is fine to use for optimizing logistic regression and linear support vector machines. For many problems, SGD will be required in order to train the SVM model in a reasonable timeframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and Encoding Data for Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassBalance(ax=<matplotlib.axes._subplots.AxesSubplot object at 0x00000207C85EB438>,\n",
       "       colormap=None, colors=None,\n",
       "       labels=['Entire home/apt', 'Private room', 'Shared room'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD3CAYAAAD10FRmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFGlJREFUeJzt3X2wnOVZx/HvCSEntSaZKtTWsYgO5RI9g5W1DZQEMh3akFLF4Q/NaMsUlcExWlFm6AsUogNtcVq0WHwLMihjpmNBZiiaFi3KJEec1J040xW8MjBWZuzLlLQhQWAxyfGPfaLLye552bNnd8/e389fz97PtZvr3ht++5xnX56JmZkZJEllWTXsBiRJg2f4S1KBDH9JKpDhL0kFWj3sBhaiXq9PAm8Fvg4cH3I7krRSnAa8EfhyrVZrtu9YEeFPK/j3DrsJSVqhNgP72gdWSvh/HeDcc89lzZo1w+6FRqPB1NTUsNtYNuM+Pxj/OTq/la8fc3zllVc4ePAgVBnabqWE/3GANWvWMDk5OexeAEamj+Uy7vOD8Z+j81v5+jjHU06X+4avJBXI8JekAhn+klQgw1+SCmT4S1KBDH9JKpDhL0kFMvwlqUAr5UteKtxpN9zf/wfd/WRfHub4p97Xl8eRBmlB4R8RG4E7MnNLRLwe2AW8jtaPBl2dmc9ExLXAdcAx4LbMfCQizgB2A68BvgZck5kvdqrt+8wkSV3Ne9onIm4E7gHWVkO/C/xlZl4C3Az8SES8AfgAcDGwFfh4REwCtwC7M3MzcAC4bo5aSdKALOSc/zPAVW23LwZ+ICL+HvgF4B+BtwHTmdnMzOeBp4HzgU3AF6r77QEum6NWkjQg8572ycwHI+LstqGzge9k5mURcQvwQeAg8HxbzVFgA7C+bbzTWPv4vBqNxkLKBqJerw+7hWU17vPrp1F9rka1r34Z9/nB8s6xlzd8DwEPV9ufB24H/gVY11azDjgMHKm2X+owNrt2XlNTUyPxS371ep1arTbsNpbNSM6vT2/OLoeRe64Y0TXso3GfH/Rnjs1ms+tBcy8f9dwHvLvavgT4N2A/sDki1kbEBuA8oAFMt9Vuo3VBlm61kqQB6SX8bwCujoh/Ai4HPpaZ3wDuohXujwE3ZebLwG3A9oiYBi4CPjNHrSRpQBZ02iczvwpcWG3/J/DODjW7aH0EtH3sm7ReIOatlSQNjt/wlaQCGf6SVCDDX5IKZPhLUoEMf0kqkOEvSQUy/CWpQIa/JBWoiIu5jPKFQMCLgUgaPI/8JalAhr8kFcjwl6QCGf6SVCDDX5IKZPhLUoEMf0kqkOEvSQUy/CWpQAv6hm9EbATuyMwtbWM/D/x6Zl5U3b4WuA44BtyWmY9ExBnAbuA1wNeAazLzxU61fZyTJGke8x75R8SNwD3A2raxtwC/BExUt98AfAC4GNgKfDwiJoFbgN2ZuRk4AFw3R60kaUAWcuT/DHAVcD9ARHwv8Angev7/IuxvA6Yzswk0I+Jp4HxgE/CxqmZPtf1Ml9ovz9dIo9FY4LRWlnq9PuwWTjGKPY2qUX2uRrWvfhn3+cHyznHe8M/MByPibICIOA34M+A3gZfaytYDz7fdPgpsmDXeaax9fF5TU1NMTvbwR0Iff4RtOdRqtWG38Cr1en3kehrlNRy554oRXcM+Gvf5QX/m2Gw2ux40L/ZXPWvAm4E/onUa6Ecj4veBx4B1bXXrgMPAkWr7pQ5js2slSQOyqPDPzP3AjwFUfw18NjOvr87j3x4Ra4FJ4DygAUwD7wbuA7YBe4H9XWolSQPSl496ZuY3gLtohftjwE2Z+TJwG7A9IqaBi4DPzFErSRqQBR35Z+ZXgQvnGsvMXfz/G8Anx74JXN7h8U6plSQNjl/ykqQCGf6SVCDDX5IKZPhLUoEMf0kqkOEvSQUy/CWpQIa/JBXI8JekAhn+klQgw1+SCmT4S1KBDH9JKpDhL0kFMvwlqUCGvyQVyPCXpAIt6EpeEbERuCMzt0TEW4A/AI4DTeDqzPxmRFwLXAccA27LzEci4gxgN/Aa4GvANZn5Yqfavs9MktTVvEf+EXEjcA+wthr6NPDrmbkF+Gvgg9UF3D8AXAxsBT4eEZPALcDuzNwMHACum6NWkjQgCznt8wxwVdvt7Zn5r9X2auBl4G3AdGY2M/N54GngfGAT8IWqdg9w2Ry1kqQBmfe0T2Y+GBFnt93+OkBEvB34NeASWkfwz7fd7SiwAVjfNt5prH18Xo1GYyFlK069Xh92C6cYxZ5G1ag+V6PaV7+M+/xgeee4oHP+s0XEzwE3AVdk5rci4giwrq1kHXAYODn+Uoex2bXzmpqaYnKyhzNEu59c/H0GqFarDbuFV6nX6yPX0yiv4cg9V4zoGvbRuM8P+jPHZrPZ9aB50eEfEe+l9Wbtlsz8djW8H7g9ItYCk8B5QAOYBt4N3AdsA/bOUStJGpBFfdQzIk4D7qJ1tP7XEfGPEfHbmfmNanwv8BhwU2a+DNwGbI+IaeAi4DNz1EqSBmRBR/6Z+VXgwurm93Sp2QXsmjX2TeDyhdRKkgbHL3lJUoEMf0kqkOEvSQUy/CWpQIa/JBXI8JekAhn+klQgw1+SCmT4S1KBDH9JKpDhL0kFMvwlqUCGvyQVyPCXpAIZ/pJUIMNfkgpk+EtSgRZ0Ja+I2AjckZlbIuIcWtfknaF17d0dmXkiIm4FrgCOAddn5v7F1PZ5XpKkOcx75B8RNwL3AGuroTuBmzNzMzABXBkRFwCXAhuB7cDdPdRKkgZkIad9ngGuartdAx6vtvcAlwGbgEczcyYznwVWR8SZi6yVJA3IvKd9MvPBiDi7bWgiM2eq7aPABmA9cKit5uT4Ymq/NV8vjUZjvpIVqV6vD7uFU4xiT6NqVJ+rUe2rX8Z9frC8c1zQOf9ZTrRtrwMOA0eq7dnji6md19TUFJOTk4vvePeTi7/PANVqtWG38Cr1en3kehrlNRy554oRXcM+Gvf5QX/m2Gw2ux409/JpnwMRsaXa3gbsBaaBrRGxKiLOAlZl5nOLrJUkDUgvR/43ALsiYg3wFPBAZh6PiL3AE7ReUHb0UCtJGpAFhX9mfhW4sNo+SOvTOrNrdgI7Z40tuFaSNDh+yUuSCmT4S1KBDH9JKpDhL0kFMvwlqUCGvyQVyPCXpAIZ/pJUIMNfkgpk+EtSgQx/SSqQ4S9JBTL8JalAhr8kFcjwl6QCGf6SVCDDX5IKZPhLUoF6uYYvEXE68OfA2cBx4FrgGHAfMAM0gB2ZeSIibgWuqPZfn5n7I+KcTrVLmokkacF6PfJ/N7A6M98O/A5wO3AncHNmbgYmgCsj4gJa1/DdCGwH7q7uf0pt71OQJC1WT0f+wEFgdUSsAtYD/0PrAu+PV/v3AO8CEng0M2eAZyNidUScCdQ61D403z/aaDR6bHe01ev1YbdwilHsaVSN6nM1qn31y7jPD5Z3jr2G/wu0Tvn8O3AG8B7gkirkAY4CG2i9MBxqu9/J8YkOtfOamppicnJy8d3ufnLx9xmgWq027BZepV6vj1xPo7yGI/dcMaJr2EfjPj/ozxybzWbXg+ZeT/v8JvDFzDwX+HFa5//XtO1fBxwGjlTbs8dPdBiTJA1Ir+H/HeD5avvbwOnAgYjYUo1tA/YC08DWiFgVEWcBqzLzuS61kqQB6fW0z+8B90bEXlpH/B8B/gXYFRFrgKeABzLzeFXzBK0Xmh3V/W+YXbuEOUiSFqmn8M/MF4Cf7bDr0g61O4Gds8YOdqqVJA2GX/KSpAIZ/pJUIMNfkgpk+EtSgQx/SSqQ4S9JBTL8JalAhr8kFcjwl6QCGf6SVCDDX5IKZPhLUoEMf0kqkOEvSQUy/CWpQIa/JBXI8JekAvV6GUci4sPAT9O6jOMfAo8D9wEzQAPYkZknIuJW4ArgGHB9Zu6PiHM61S5hHpKkRejpyL+6+PrbgYtpXY7xTcCdwM2ZuRmYAK6MiAuq/RuB7cDd1UOcUruEOUiSFqnX0z5bga8ADwGfBx4BarSO/gH2AJcBm4BHM3MmM58FVkfEmV1qJUkD0utpnzOAHwTeA/wQ8DCwKjNnqv1HgQ3AeuBQ2/1Ojk90qJ1Xo9Hosd3RVq/Xh93CKUaxp1E1qs/VqPbVL+M+P1jeOfYa/oeAf8/MV4CMiJdpnfo5aR1wGDhSbc8eP9FhbF5TU1NMTk4uvtvdTy7+PgNUq9WG3cKr1Ov1ketplNdw5J4rRnQN+2jc5wf9mWOz2ex60NzraZ99wOURMRER3w+8FvhS9V4AwDZgLzANbI2IVRFxFq2/Dp4DDnSolSQNSE9H/pn5SERcAuyn9QKyA/gPYFdErAGeAh7IzOMRsRd4oq0O4IbZtUubhiRpMXr+qGdm3thh+NIOdTuBnbPGDnaqlSQNhl/ykqQCGf6SVCDDX5IKZPhLUoEMf0kqkOEvSQUy/CWpQIa/JBXI8JekAhn+klQgw1+SCmT4S1KBDH9JKpDhL0kFMvwlqUCGvyQVyPCXpAL1fCUvgIh4PVAH3gkcA+4DZoAGsCMzT0TErcAV1f7rM3N/RJzTqXYpvUiSFq7nI/+IOB34E+ClauhO4ObM3AxMAFdGxAW0Lte4EdgO3N2tttc+JEmLt5Qj/08Cfwx8uLpdAx6vtvcA7wISeDQzZ4BnI2J1RJzZpfahJfQiDc19+z407BY6+sq+zwHw/k2fGHInGkU9hX9EvB/4VmZ+MSJOhv9EFfIAR4ENwHrgUNtdT453qp1Xo9Hopd2RV6/Xh93CKUaxJ/VmXNdyXOfVbjnn2OuR/y8CMxFxGfAW4C+A17ftXwccBo5U27PHT3QYm9fU1BSTk5OL73b3k4u/zwDVarVht/Aq9Xp95Hoa9TUcZSO3ln0wkv+N9lk/5thsNrseNPd0zj8zL8nMSzNzC/CvwNXAnojYUpVsA/YC08DWiFgVEWcBqzLzOeBAh1pJ0oAs6dM+s9wA7IqINcBTwAOZeTwi9gJP0Hqh2dGtto99rDijeM7Y88XSeFty+FdH/ydd2mH/TmDnrLGDnWolSYPhl7wkqUCGvyQVyPCXpAIZ/pJUIMNfkgpk+EtSgQx/SSqQ4S9JBTL8JalAhr8kFcjwl6QCGf6SVCDDX5IKZPhLUoEMf0kqkOEvSQUy/CWpQIa/JBWop8s4RsTpwL3A2cAkcBvwJHAfMAM0gB2ZeSIibgWuAI4B12fm/og4p1PtkmYiSVqwXo/83wscyszNwDbgM8CdwM3V2ARwZURcQOtavRuB7cDd1f1Pqe19CpKkxer1Au6fAx5ou30MqAGPV7f3AO8CEng0M2eAZyNidUSc2aX2ofn+0Uaj0WO76lW9Xh92C1qicV3DcZ1Xu+WcY0/hn5kvAETEOlovAjcDn6xCHuAosAFYDxxqu+vJ8YkOtfOamppicnJy8Q3vfnLx9xEAtVpt2C20uIY9G5k17KN6vT6W82rXjzk2m82uB809v+EbEW8C/gG4PzN3A+3n7NcBh4Ej1fbs8U61kqQB6Sn8I+L7gEeBD2bmvdXwgYjYUm1vA/YC08DWiFgVEWcBqzLzuS61kqQB6fWc/0eA1wEfjYiPVmO/AdwVEWuAp4AHMvN4ROwFnqD1QrOjqr0B2NVe2+sEJEmL1+s5/9+gFfazXdqhdiewc9bYwU61kqTB8EteklQgw1+SCmT4S1KBDH9JKpDhL0kFMvwlqUCGvyQVyPCXpAIZ/pJUoF5/3kGSFuW0G+7v7wP28Zdej3/qfX17rJXCI39JKpDhL0kFMvwlqUCGvyQVyPCXpAIZ/pJUIMNfkgo0tM/5R8Qq4A+BHweawC9n5tPD6kdSue7b96Fht9DRV/Z9DoD3b/pE3x97mEf+PwOszcyLgA8BnxpiL5JUlGF+w3cT8AWAzPzniPjJOWpPA3jllVd6+ofe+NrTe7rfoJw+8V3DbqGrZrM57BaA0V7DUV4/cA0XYlzXsC0zT5u9b2JmZmYJLfUuIu4BHszMPdXtZ4Efzsxjs2vr9fomYO+AW5SkcbG5Vqvtax8Y5pH/EWBd2+1VnYK/8mVgM/B14PhyNyZJY+I04I20MvRVhhn+08BPAX8VERcCX+lWWKvVmsC+bvslSV0902lwmOH/EPDOiPgnYAK4Zoi9SFJRhnbOX5I0PH7JS5IKZPhLUoEMf0kqkJdx7GK+n5+IiGuB64BjwG2Z+chQGl2CBczxLuBi4Gg1dGVmPj/wRpcoIjYCd2TmllnjPwXcQmsN783MXUNob8nmmN9vAb8EfKsaui4zc8DtLUlEnA7cC5wNTNL6f+3htv0reg0XML9lW0PDv7v/+/mJ6qOonwKuBIiINwAfAH4SWAvsi4i/y8zR+CrlwnWdY+UCYGtmPjeU7vogIm4E3gf896zx04HfA95a7ZuOiM9n5jcG32Xvus2vcgFwdWbWB9tVX70XOJSZ74uI7wUOAA/D2Kxh1/lVlm0NPe3T3at+foJW0J/0NmA6M5vVkfDTwPmDb3HJus6x+qvgzcCfRsR0RPzicFpcsmeAqzqMnwc8nZnfycxXaH2PZPNAO+uPbvMDqAEfjoh9EfHhAfbUT58DPtp2u/2LoOOwhnPND5ZxDQ3/7tYD7ac4jkfE6i77jgIbBtVYH801x9cCf0DryORy4FcjYsW9wGXmg8D/dNg1Fms4x/wAPgv8CvAOYFNEvGdgjfVJZr6QmUcjYh3wAHBz2+4Vv4bzzA+WcQ0N/+7m+vmJ2fvWAYcH1VgfzTXHF4FPZ+aLmXkUeIzWewPjYlzWsKOImAB+PzOfq46K/wb4iSG31ZOIeBPwD8D9mbm7bddYrGG3+S33GnrOv7u5fn5iP3B7RKyl9SbNeUBj8C0u2VxzPBf4bERcQOsgYRPw54Nvcdk8Bbw5Ir4HeAG4BPjkcFvqq/VAIyLOo3U+/B203lhcUSLi+4BHgV/LzC/N2r3i13Ce+S3rGhr+3Z3y8xPVO+9PZ+bD1Sdh9tIKxpsy8+Uh9tqr+eb4l8A/0zqt8BeZ+W9D7LUvIuLnge/OzD+t5vpFWmt4b2b+13C7W7pZ8/sIrSPKJvClzPzb4XbXk48ArwM+GhEnz43vAl47Jms43/yWbQ39eQdJKpDn/CWpQIa/JBXI8JekAhn+klQgw1+SCmT4S1KBDH9JKtD/AqkCSh3XaA5aAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "classes_test = ClassBalance(\n",
    "    labels=['Entire home/apt', 'Private room', 'Shared room'])\n",
    "classes_test.fit(y_train['Response'], y_test['Response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data set into 80% Train and 20% Test. The bar graph above shows the split by level of our response variable room type. Its good to note that 'Shared room' has a small number of observations compared to the other two classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transforms\n",
    "- One Hot Encode all categoricals\n",
    "- Standard Scale all numerics (sklearn is not R - it does not do this by default)\n",
    "- This needs to be done on train/test set separately (create a pipeline) \n",
    "\n",
    "https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/compose.html#combining-estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbourhood_group was OHE'd\n",
      "latitude was Standard Scaled\n",
      "longitude was Standard Scaled\n",
      "price was Standard Scaled\n",
      "minimum_nights was Standard Scaled\n",
      "number_of_reviews was Standard Scaled\n",
      "reviews_per_month was Standard Scaled\n",
      "calculated_host_listings_count was Standard Scaled\n",
      "availability_365 was Standard Scaled\n",
      "dist_subway was Standard Scaled\n",
      "cnt_all was Standard Scaled\n",
      "cnt_entire_home was Standard Scaled\n",
      "cnt_private_room was Standard Scaled\n",
      "cnt_shared_room was Standard Scaled\n",
      "avgprice_all was Standard Scaled\n",
      "avgprice_entire_home was Standard Scaled\n",
      "avgprice_private_room was Standard Scaled\n",
      "avgprice_shared_room was Standard Scaled\n",
      "days_since_last_review was Standard Scaled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "#OH encode\n",
    "label_encode = [\n",
    "    x for x, y in dict(X_train.dtypes).items()\n",
    "    if type(y) == pd.CategoricalDtype\n",
    "]\n",
    "for var in label_encode:\n",
    "    #impute to Mode\n",
    "    print(f\"{var} was OHE'd\")\n",
    "    X_train[var].fillna(X_train[var].mode()[0], inplace=True)\n",
    "    X_test[var].fillna(X_train[var].mode()[0], inplace=True)\n",
    "    cat_list_train = pd.get_dummies(X_train[var], prefix=var)\n",
    "    cat_list_test = pd.get_dummies(X_test[var], prefix=var)\n",
    "    X_train_new = X_train.join(cat_list_train)\n",
    "    X_train = X_train_new\n",
    "    X_test_new = X_test.join(cat_list_test)\n",
    "    X_test = X_test_new\n",
    "\n",
    "normalize = [x for x, y in dict(X_train.dtypes).items() if y == np.float64]\n",
    "for col in normalize:\n",
    "    #change impution scheme?\n",
    "    print(f\"{col} was Standard Scaled\")\n",
    "    X_train[col].fillna(X_train[col].median(), inplace=True)\n",
    "    X_test[col].fillna(X_train[col].median(), inplace=True)\n",
    "    normalizer = StandardScaler()\n",
    "    ar_train = X_train[col].to_numpy().reshape(-1, 1)\n",
    "    normalizer.fit(ar_train)\n",
    "    X_train.loc[:, col] = normalizer.transform(ar_train)\n",
    "    ar_test = X_test[col].to_numpy().reshape(-1, 1)\n",
    "    X_test.loc[:, col] = normalizer.transform(ar_test)\n",
    "\n",
    "X_train.drop(columns=label_encode, inplace=True)\n",
    "X_test.drop(columns=label_encode, inplace=True)\n",
    "X_train.drop(columns=target_col, inplace=True)\n",
    "X_test.drop(columns=target_col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_0': 0.46599676455948236, 'class_1': 0.5083685913389746, 'class_2': 0.025634644101543057}\n",
      "{'class_0': 0.4682677949228472, 'class_1': 0.5068442010950722, 'class_2': 0.024888003982080638}\n"
     ]
    }
   ],
   "source": [
    "base_line_accuracy_train = {\n",
    "    'class_0': (y_train[y_train.Response == 0].shape[0] / y_train.shape[0]),\n",
    "    'class_1': (y_train[y_train.Response == 1].shape[0] / y_train.shape[0]),\n",
    "    'class_2': (y_train[y_train.Response == 2].shape[0] / y_train.shape[0])\n",
    "}\n",
    "base_line_accuracy_test = {\n",
    "    'class_0': (y_test[y_test.Response == 0].shape[0] / y_test.shape[0]),\n",
    "    'class_1': (y_test[y_test.Response == 1].shape[0] / y_test.shape[0]),\n",
    "    'class_2': (y_test[y_test.Response == 2].shape[0] / y_test.shape[0])\n",
    "}\n",
    "\n",
    "print(base_line_accuracy_train)\n",
    "print(base_line_accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could achieve 50% - 51% accuracy by predicting class 1 all the time (Private room). Hopefully our models do better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\William\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1297: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 16.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (Accuracy score=0.813):\n",
      "{'logistic__C': 21.54434690031882, 'logistic__penalty': 'l1'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logistic__C</th>\n",
       "      <th>param_logistic__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.181091</td>\n",
       "      <td>0.012333</td>\n",
       "      <td>0.013336</td>\n",
       "      <td>0.005793</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0001, 'logistic__penalty': '...</td>\n",
       "      <td>0.465982</td>\n",
       "      <td>0.465982</td>\n",
       "      <td>0.466026</td>\n",
       "      <td>0.465997</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>20</td>\n",
       "      <td>0.466004</td>\n",
       "      <td>0.466004</td>\n",
       "      <td>0.465982</td>\n",
       "      <td>0.465997</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.680541</td>\n",
       "      <td>0.059619</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0001, 'logistic__penalty': '...</td>\n",
       "      <td>0.762483</td>\n",
       "      <td>0.761176</td>\n",
       "      <td>0.754807</td>\n",
       "      <td>0.759489</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>19</td>\n",
       "      <td>0.758925</td>\n",
       "      <td>0.759485</td>\n",
       "      <td>0.759496</td>\n",
       "      <td>0.759302</td>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017337</td>\n",
       "      <td>0.005560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'logistic__C': 0.0001, 'logistic__penalty': '...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013676</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>none</td>\n",
       "      <td>{'logistic__C': 0.0001, 'logistic__penalty': '...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.233079</td>\n",
       "      <td>0.031146</td>\n",
       "      <td>0.011334</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.000774264</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.000774263682681127, 'logisti...</td>\n",
       "      <td>0.781988</td>\n",
       "      <td>0.783854</td>\n",
       "      <td>0.776367</td>\n",
       "      <td>0.780737</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>18</td>\n",
       "      <td>0.780111</td>\n",
       "      <td>0.779178</td>\n",
       "      <td>0.782921</td>\n",
       "      <td>0.780737</td>\n",
       "      <td>0.001591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.020899</td>\n",
       "      <td>0.111115</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.000774264</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.000774263682681127, 'logisti...</td>\n",
       "      <td>0.795334</td>\n",
       "      <td>0.800933</td>\n",
       "      <td>0.796061</td>\n",
       "      <td>0.797443</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>17</td>\n",
       "      <td>0.800271</td>\n",
       "      <td>0.795837</td>\n",
       "      <td>0.798413</td>\n",
       "      <td>0.798174</td>\n",
       "      <td>0.001818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.024673</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000774264</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'logistic__C': 0.000774263682681127, 'logisti...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.018675</td>\n",
       "      <td>0.006026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000774264</td>\n",
       "      <td>none</td>\n",
       "      <td>{'logistic__C': 0.000774263682681127, 'logisti...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.475437</td>\n",
       "      <td>0.041502</td>\n",
       "      <td>0.010671</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.00599484</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.005994842503189409, 'logisti...</td>\n",
       "      <td>0.806160</td>\n",
       "      <td>0.809706</td>\n",
       "      <td>0.804555</td>\n",
       "      <td>0.806807</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>16</td>\n",
       "      <td>0.807831</td>\n",
       "      <td>0.804424</td>\n",
       "      <td>0.808119</td>\n",
       "      <td>0.806791</td>\n",
       "      <td>0.001678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.685053</td>\n",
       "      <td>0.132005</td>\n",
       "      <td>0.016377</td>\n",
       "      <td>0.007520</td>\n",
       "      <td>0.00599484</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.005994842503189409, 'logisti...</td>\n",
       "      <td>0.809426</td>\n",
       "      <td>0.811666</td>\n",
       "      <td>0.806795</td>\n",
       "      <td>0.809296</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>15</td>\n",
       "      <td>0.809837</td>\n",
       "      <td>0.808484</td>\n",
       "      <td>0.810079</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>0.000702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.041010</td>\n",
       "      <td>0.012836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00599484</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'logistic__C': 0.005994842503189409, 'logisti...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.020336</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00599484</td>\n",
       "      <td>none</td>\n",
       "      <td>{'logistic__C': 0.005994842503189409, 'logisti...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.288963</td>\n",
       "      <td>0.066851</td>\n",
       "      <td>0.012335</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.0464159</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.046415888336127774, 'logisti...</td>\n",
       "      <td>0.811759</td>\n",
       "      <td>0.813066</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.812033</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>14</td>\n",
       "      <td>0.811610</td>\n",
       "      <td>0.811004</td>\n",
       "      <td>0.812692</td>\n",
       "      <td>0.811769</td>\n",
       "      <td>0.000698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.465896</td>\n",
       "      <td>0.256529</td>\n",
       "      <td>0.012668</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.0464159</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.046415888336127774, 'logisti...</td>\n",
       "      <td>0.811666</td>\n",
       "      <td>0.813626</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.812189</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>13</td>\n",
       "      <td>0.812684</td>\n",
       "      <td>0.811004</td>\n",
       "      <td>0.812832</td>\n",
       "      <td>0.812173</td>\n",
       "      <td>0.000829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.019002</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0464159</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'logistic__C': 0.046415888336127774, 'logisti...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.026340</td>\n",
       "      <td>0.008579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0464159</td>\n",
       "      <td>none</td>\n",
       "      <td>{'logistic__C': 0.046415888336127774, 'logisti...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.593150</td>\n",
       "      <td>0.403500</td>\n",
       "      <td>0.013006</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.359381</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.3593813663804626, 'logistic_...</td>\n",
       "      <td>0.812039</td>\n",
       "      <td>0.815026</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.812780</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>11</td>\n",
       "      <td>0.813197</td>\n",
       "      <td>0.811657</td>\n",
       "      <td>0.813859</td>\n",
       "      <td>0.812904</td>\n",
       "      <td>0.000922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.227401</td>\n",
       "      <td>0.108686</td>\n",
       "      <td>0.009003</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.359381</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.3593813663804626, 'logistic_...</td>\n",
       "      <td>0.811853</td>\n",
       "      <td>0.814466</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.812531</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>12</td>\n",
       "      <td>0.813290</td>\n",
       "      <td>0.811517</td>\n",
       "      <td>0.813906</td>\n",
       "      <td>0.812904</td>\n",
       "      <td>0.001013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.025007</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359381</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'logistic__C': 0.3593813663804626, 'logistic_...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.017670</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359381</td>\n",
       "      <td>none</td>\n",
       "      <td>{'logistic__C': 0.3593813663804626, 'logistic_...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12.422677</td>\n",
       "      <td>0.835754</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>2.78256</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 2.782559402207126, 'logistic__...</td>\n",
       "      <td>0.812319</td>\n",
       "      <td>0.815306</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.812967</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>9</td>\n",
       "      <td>0.814084</td>\n",
       "      <td>0.811937</td>\n",
       "      <td>0.813906</td>\n",
       "      <td>0.813309</td>\n",
       "      <td>0.000973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.418537</td>\n",
       "      <td>0.175571</td>\n",
       "      <td>0.011005</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>2.78256</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 2.782559402207126, 'logistic__...</td>\n",
       "      <td>0.812319</td>\n",
       "      <td>0.815119</td>\n",
       "      <td>0.811182</td>\n",
       "      <td>0.812873</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>10</td>\n",
       "      <td>0.814084</td>\n",
       "      <td>0.811937</td>\n",
       "      <td>0.813906</td>\n",
       "      <td>0.813309</td>\n",
       "      <td>0.000973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.018669</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.78256</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'logistic__C': 2.782559402207126, 'logistic__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.022673</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.78256</td>\n",
       "      <td>none</td>\n",
       "      <td>{'logistic__C': 2.782559402207126, 'logistic__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20.977367</td>\n",
       "      <td>2.267163</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>21.5443</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 21.54434690031882, 'logistic__...</td>\n",
       "      <td>0.812319</td>\n",
       "      <td>0.815399</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.812998</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814084</td>\n",
       "      <td>0.811984</td>\n",
       "      <td>0.813859</td>\n",
       "      <td>0.813309</td>\n",
       "      <td>0.000941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.394231</td>\n",
       "      <td>0.120986</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>21.5443</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 21.54434690031882, 'logistic__...</td>\n",
       "      <td>0.812319</td>\n",
       "      <td>0.815399</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.812998</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814084</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.813859</td>\n",
       "      <td>0.813324</td>\n",
       "      <td>0.000920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.026673</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.5443</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'logistic__C': 21.54434690031882, 'logistic__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.024343</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.5443</td>\n",
       "      <td>none</td>\n",
       "      <td>{'logistic__C': 21.54434690031882, 'logistic__...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13.687139</td>\n",
       "      <td>6.496149</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>166.81</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 166.81005372000558, 'logistic_...</td>\n",
       "      <td>0.812319</td>\n",
       "      <td>0.815399</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.812998</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814130</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.813812</td>\n",
       "      <td>0.813324</td>\n",
       "      <td>0.000924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.659638</td>\n",
       "      <td>0.131607</td>\n",
       "      <td>0.014341</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>166.81</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 166.81005372000558, 'logistic_...</td>\n",
       "      <td>0.812319</td>\n",
       "      <td>0.815399</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.812998</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814130</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.813859</td>\n",
       "      <td>0.813340</td>\n",
       "      <td>0.000933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.027673</td>\n",
       "      <td>0.006597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>166.81</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'logistic__C': 166.81005372000558, 'logistic_...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.030676</td>\n",
       "      <td>0.005437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>166.81</td>\n",
       "      <td>none</td>\n",
       "      <td>{'logistic__C': 166.81005372000558, 'logistic_...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.526748</td>\n",
       "      <td>0.093697</td>\n",
       "      <td>0.014672</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>1291.55</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 1291.5496650148827, 'logistic_...</td>\n",
       "      <td>0.812319</td>\n",
       "      <td>0.815399</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.812998</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814130</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.813766</td>\n",
       "      <td>0.813309</td>\n",
       "      <td>0.000916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.539714</td>\n",
       "      <td>0.068674</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>1291.55</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 1291.5496650148827, 'logistic_...</td>\n",
       "      <td>0.812319</td>\n",
       "      <td>0.815399</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.812998</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814130</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.813859</td>\n",
       "      <td>0.813340</td>\n",
       "      <td>0.000933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.034008</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1291.55</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'logistic__C': 1291.5496650148827, 'logistic_...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.037342</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1291.55</td>\n",
       "      <td>none</td>\n",
       "      <td>{'logistic__C': 1291.5496650148827, 'logistic_...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.502803</td>\n",
       "      <td>0.083432</td>\n",
       "      <td>0.011334</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>10000</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 10000.0, 'logistic__penalty': ...</td>\n",
       "      <td>0.812319</td>\n",
       "      <td>0.815399</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.812998</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814130</td>\n",
       "      <td>0.811984</td>\n",
       "      <td>0.813859</td>\n",
       "      <td>0.813324</td>\n",
       "      <td>0.000954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.058524</td>\n",
       "      <td>0.184047</td>\n",
       "      <td>0.007336</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>10000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 10000.0, 'logistic__penalty': ...</td>\n",
       "      <td>0.812319</td>\n",
       "      <td>0.815399</td>\n",
       "      <td>0.811275</td>\n",
       "      <td>0.812998</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>1</td>\n",
       "      <td>0.814130</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>0.813859</td>\n",
       "      <td>0.813340</td>\n",
       "      <td>0.000933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.031674</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'logistic__C': 10000.0, 'logistic__penalty': ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.028676</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000</td>\n",
       "      <td>none</td>\n",
       "      <td>{'logistic__C': 10000.0, 'logistic__penalty': ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.181091      0.012333         0.013336        0.005793   \n",
       "1        0.680541      0.059619         0.010334        0.003301   \n",
       "2        0.017337      0.005560         0.000000        0.000000   \n",
       "3        0.013676      0.001257         0.000000        0.000000   \n",
       "4        0.233079      0.031146         0.011334        0.002357   \n",
       "5        1.020899      0.111115         0.009334        0.002625   \n",
       "6        0.024673      0.012288         0.000000        0.000000   \n",
       "7        0.018675      0.006026         0.000000        0.000000   \n",
       "8        0.475437      0.041502         0.010671        0.001245   \n",
       "9        1.685053      0.132005         0.016377        0.007520   \n",
       "10       0.041010      0.012836         0.000000        0.000000   \n",
       "11       0.020336      0.005439         0.000000        0.000000   \n",
       "12       1.288963      0.066851         0.012335        0.001248   \n",
       "13       2.465896      0.256529         0.012668        0.002055   \n",
       "14       0.019002      0.006376         0.000000        0.000000   \n",
       "15       0.026340      0.008579         0.000000        0.000000   \n",
       "16       3.593150      0.403500         0.013006        0.002941   \n",
       "17       3.227401      0.108686         0.009003        0.000821   \n",
       "18       0.025007      0.006977         0.000000        0.000000   \n",
       "19       0.017670      0.000942         0.000000        0.000000   \n",
       "20      12.422677      0.835754         0.004333        0.000470   \n",
       "21       3.418537      0.175571         0.011005        0.002157   \n",
       "22       0.018669      0.001699         0.000000        0.000000   \n",
       "23       0.022673      0.007321         0.000000        0.000000   \n",
       "24      20.977367      2.267163         0.003668        0.000471   \n",
       "25       3.394231      0.120986         0.010334        0.001250   \n",
       "26       0.026673      0.001248         0.000000        0.000000   \n",
       "27       0.024343      0.002628         0.000000        0.000000   \n",
       "28      13.687139      6.496149         0.004999        0.002162   \n",
       "29       3.659638      0.131607         0.014341        0.004925   \n",
       "30       0.027673      0.006597         0.000000        0.000000   \n",
       "31       0.030676      0.005437         0.000000        0.000000   \n",
       "32       1.526748      0.093697         0.014672        0.001248   \n",
       "33       3.539714      0.068674         0.010668        0.000473   \n",
       "34       0.034008      0.005096         0.000000        0.000000   \n",
       "35       0.037342      0.002497         0.000000        0.000000   \n",
       "36       1.502803      0.083432         0.011334        0.001246   \n",
       "37       3.058524      0.184047         0.007336        0.001245   \n",
       "38       0.031674      0.003399         0.000000        0.000000   \n",
       "39       0.028676      0.001246         0.000000        0.000000   \n",
       "\n",
       "   param_logistic__C param_logistic__penalty  \\\n",
       "0             0.0001                      l1   \n",
       "1             0.0001                      l2   \n",
       "2             0.0001              elasticnet   \n",
       "3             0.0001                    none   \n",
       "4        0.000774264                      l1   \n",
       "5        0.000774264                      l2   \n",
       "6        0.000774264              elasticnet   \n",
       "7        0.000774264                    none   \n",
       "8         0.00599484                      l1   \n",
       "9         0.00599484                      l2   \n",
       "10        0.00599484              elasticnet   \n",
       "11        0.00599484                    none   \n",
       "12         0.0464159                      l1   \n",
       "13         0.0464159                      l2   \n",
       "14         0.0464159              elasticnet   \n",
       "15         0.0464159                    none   \n",
       "16          0.359381                      l1   \n",
       "17          0.359381                      l2   \n",
       "18          0.359381              elasticnet   \n",
       "19          0.359381                    none   \n",
       "20           2.78256                      l1   \n",
       "21           2.78256                      l2   \n",
       "22           2.78256              elasticnet   \n",
       "23           2.78256                    none   \n",
       "24           21.5443                      l1   \n",
       "25           21.5443                      l2   \n",
       "26           21.5443              elasticnet   \n",
       "27           21.5443                    none   \n",
       "28            166.81                      l1   \n",
       "29            166.81                      l2   \n",
       "30            166.81              elasticnet   \n",
       "31            166.81                    none   \n",
       "32           1291.55                      l1   \n",
       "33           1291.55                      l2   \n",
       "34           1291.55              elasticnet   \n",
       "35           1291.55                    none   \n",
       "36             10000                      l1   \n",
       "37             10000                      l2   \n",
       "38             10000              elasticnet   \n",
       "39             10000                    none   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'logistic__C': 0.0001, 'logistic__penalty': '...           0.465982   \n",
       "1   {'logistic__C': 0.0001, 'logistic__penalty': '...           0.762483   \n",
       "2   {'logistic__C': 0.0001, 'logistic__penalty': '...           0.000000   \n",
       "3   {'logistic__C': 0.0001, 'logistic__penalty': '...           0.000000   \n",
       "4   {'logistic__C': 0.000774263682681127, 'logisti...           0.781988   \n",
       "5   {'logistic__C': 0.000774263682681127, 'logisti...           0.795334   \n",
       "6   {'logistic__C': 0.000774263682681127, 'logisti...           0.000000   \n",
       "7   {'logistic__C': 0.000774263682681127, 'logisti...           0.000000   \n",
       "8   {'logistic__C': 0.005994842503189409, 'logisti...           0.806160   \n",
       "9   {'logistic__C': 0.005994842503189409, 'logisti...           0.809426   \n",
       "10  {'logistic__C': 0.005994842503189409, 'logisti...           0.000000   \n",
       "11  {'logistic__C': 0.005994842503189409, 'logisti...           0.000000   \n",
       "12  {'logistic__C': 0.046415888336127774, 'logisti...           0.811759   \n",
       "13  {'logistic__C': 0.046415888336127774, 'logisti...           0.811666   \n",
       "14  {'logistic__C': 0.046415888336127774, 'logisti...           0.000000   \n",
       "15  {'logistic__C': 0.046415888336127774, 'logisti...           0.000000   \n",
       "16  {'logistic__C': 0.3593813663804626, 'logistic_...           0.812039   \n",
       "17  {'logistic__C': 0.3593813663804626, 'logistic_...           0.811853   \n",
       "18  {'logistic__C': 0.3593813663804626, 'logistic_...           0.000000   \n",
       "19  {'logistic__C': 0.3593813663804626, 'logistic_...           0.000000   \n",
       "20  {'logistic__C': 2.782559402207126, 'logistic__...           0.812319   \n",
       "21  {'logistic__C': 2.782559402207126, 'logistic__...           0.812319   \n",
       "22  {'logistic__C': 2.782559402207126, 'logistic__...           0.000000   \n",
       "23  {'logistic__C': 2.782559402207126, 'logistic__...           0.000000   \n",
       "24  {'logistic__C': 21.54434690031882, 'logistic__...           0.812319   \n",
       "25  {'logistic__C': 21.54434690031882, 'logistic__...           0.812319   \n",
       "26  {'logistic__C': 21.54434690031882, 'logistic__...           0.000000   \n",
       "27  {'logistic__C': 21.54434690031882, 'logistic__...           0.000000   \n",
       "28  {'logistic__C': 166.81005372000558, 'logistic_...           0.812319   \n",
       "29  {'logistic__C': 166.81005372000558, 'logistic_...           0.812319   \n",
       "30  {'logistic__C': 166.81005372000558, 'logistic_...           0.000000   \n",
       "31  {'logistic__C': 166.81005372000558, 'logistic_...           0.000000   \n",
       "32  {'logistic__C': 1291.5496650148827, 'logistic_...           0.812319   \n",
       "33  {'logistic__C': 1291.5496650148827, 'logistic_...           0.812319   \n",
       "34  {'logistic__C': 1291.5496650148827, 'logistic_...           0.000000   \n",
       "35  {'logistic__C': 1291.5496650148827, 'logistic_...           0.000000   \n",
       "36  {'logistic__C': 10000.0, 'logistic__penalty': ...           0.812319   \n",
       "37  {'logistic__C': 10000.0, 'logistic__penalty': ...           0.812319   \n",
       "38  {'logistic__C': 10000.0, 'logistic__penalty': ...           0.000000   \n",
       "39  {'logistic__C': 10000.0, 'logistic__penalty': ...           0.000000   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.465982           0.466026         0.465997        0.000021   \n",
       "1            0.761176           0.754807         0.759489        0.003353   \n",
       "2            0.000000           0.000000         0.000000        0.000000   \n",
       "3            0.000000           0.000000         0.000000        0.000000   \n",
       "4            0.783854           0.776367         0.780737        0.003182   \n",
       "5            0.800933           0.796061         0.797443        0.002486   \n",
       "6            0.000000           0.000000         0.000000        0.000000   \n",
       "7            0.000000           0.000000         0.000000        0.000000   \n",
       "8            0.809706           0.804555         0.806807        0.002152   \n",
       "9            0.811666           0.806795         0.809296        0.001991   \n",
       "10           0.000000           0.000000         0.000000        0.000000   \n",
       "11           0.000000           0.000000         0.000000        0.000000   \n",
       "12           0.813066           0.811275         0.812033        0.000756   \n",
       "13           0.813626           0.811275         0.812189        0.001028   \n",
       "14           0.000000           0.000000         0.000000        0.000000   \n",
       "15           0.000000           0.000000         0.000000        0.000000   \n",
       "16           0.815026           0.811275         0.812780        0.001618   \n",
       "17           0.814466           0.811275         0.812531        0.001388   \n",
       "18           0.000000           0.000000         0.000000        0.000000   \n",
       "19           0.000000           0.000000         0.000000        0.000000   \n",
       "20           0.815306           0.811275         0.812967        0.001708   \n",
       "21           0.815119           0.811182         0.812873        0.001654   \n",
       "22           0.000000           0.000000         0.000000        0.000000   \n",
       "23           0.000000           0.000000         0.000000        0.000000   \n",
       "24           0.815399           0.811275         0.812998        0.001751   \n",
       "25           0.815399           0.811275         0.812998        0.001751   \n",
       "26           0.000000           0.000000         0.000000        0.000000   \n",
       "27           0.000000           0.000000         0.000000        0.000000   \n",
       "28           0.815399           0.811275         0.812998        0.001751   \n",
       "29           0.815399           0.811275         0.812998        0.001751   \n",
       "30           0.000000           0.000000         0.000000        0.000000   \n",
       "31           0.000000           0.000000         0.000000        0.000000   \n",
       "32           0.815399           0.811275         0.812998        0.001751   \n",
       "33           0.815399           0.811275         0.812998        0.001751   \n",
       "34           0.000000           0.000000         0.000000        0.000000   \n",
       "35           0.000000           0.000000         0.000000        0.000000   \n",
       "36           0.815399           0.811275         0.812998        0.001751   \n",
       "37           0.815399           0.811275         0.812998        0.001751   \n",
       "38           0.000000           0.000000         0.000000        0.000000   \n",
       "39           0.000000           0.000000         0.000000        0.000000   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                20            0.466004            0.466004   \n",
       "1                19            0.758925            0.759485   \n",
       "2                21            0.000000            0.000000   \n",
       "3                21            0.000000            0.000000   \n",
       "4                18            0.780111            0.779178   \n",
       "5                17            0.800271            0.795837   \n",
       "6                21            0.000000            0.000000   \n",
       "7                21            0.000000            0.000000   \n",
       "8                16            0.807831            0.804424   \n",
       "9                15            0.809837            0.808484   \n",
       "10               21            0.000000            0.000000   \n",
       "11               21            0.000000            0.000000   \n",
       "12               14            0.811610            0.811004   \n",
       "13               13            0.812684            0.811004   \n",
       "14               21            0.000000            0.000000   \n",
       "15               21            0.000000            0.000000   \n",
       "16               11            0.813197            0.811657   \n",
       "17               12            0.813290            0.811517   \n",
       "18               21            0.000000            0.000000   \n",
       "19               21            0.000000            0.000000   \n",
       "20                9            0.814084            0.811937   \n",
       "21               10            0.814084            0.811937   \n",
       "22               21            0.000000            0.000000   \n",
       "23               21            0.000000            0.000000   \n",
       "24                1            0.814084            0.811984   \n",
       "25                1            0.814084            0.812030   \n",
       "26               21            0.000000            0.000000   \n",
       "27               21            0.000000            0.000000   \n",
       "28                1            0.814130            0.812030   \n",
       "29                1            0.814130            0.812030   \n",
       "30               21            0.000000            0.000000   \n",
       "31               21            0.000000            0.000000   \n",
       "32                1            0.814130            0.812030   \n",
       "33                1            0.814130            0.812030   \n",
       "34               21            0.000000            0.000000   \n",
       "35               21            0.000000            0.000000   \n",
       "36                1            0.814130            0.811984   \n",
       "37                1            0.814130            0.812030   \n",
       "38               21            0.000000            0.000000   \n",
       "39               21            0.000000            0.000000   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "0             0.465982          0.465997         0.000010  \n",
       "1             0.759496          0.759302         0.000267  \n",
       "2             0.000000          0.000000         0.000000  \n",
       "3             0.000000          0.000000         0.000000  \n",
       "4             0.782921          0.780737         0.001591  \n",
       "5             0.798413          0.798174         0.001818  \n",
       "6             0.000000          0.000000         0.000000  \n",
       "7             0.000000          0.000000         0.000000  \n",
       "8             0.808119          0.806791         0.001678  \n",
       "9             0.810079          0.809467         0.000702  \n",
       "10            0.000000          0.000000         0.000000  \n",
       "11            0.000000          0.000000         0.000000  \n",
       "12            0.812692          0.811769         0.000698  \n",
       "13            0.812832          0.812173         0.000829  \n",
       "14            0.000000          0.000000         0.000000  \n",
       "15            0.000000          0.000000         0.000000  \n",
       "16            0.813859          0.812904         0.000922  \n",
       "17            0.813906          0.812904         0.001013  \n",
       "18            0.000000          0.000000         0.000000  \n",
       "19            0.000000          0.000000         0.000000  \n",
       "20            0.813906          0.813309         0.000973  \n",
       "21            0.813906          0.813309         0.000973  \n",
       "22            0.000000          0.000000         0.000000  \n",
       "23            0.000000          0.000000         0.000000  \n",
       "24            0.813859          0.813309         0.000941  \n",
       "25            0.813859          0.813324         0.000920  \n",
       "26            0.000000          0.000000         0.000000  \n",
       "27            0.000000          0.000000         0.000000  \n",
       "28            0.813812          0.813324         0.000924  \n",
       "29            0.813859          0.813340         0.000933  \n",
       "30            0.000000          0.000000         0.000000  \n",
       "31            0.000000          0.000000         0.000000  \n",
       "32            0.813766          0.813309         0.000916  \n",
       "33            0.813859          0.813340         0.000933  \n",
       "34            0.000000          0.000000         0.000000  \n",
       "35            0.000000          0.000000         0.000000  \n",
       "36            0.813859          0.813324         0.000954  \n",
       "37            0.813859          0.813340         0.000933  \n",
       "38            0.000000          0.000000         0.000000  \n",
       "39            0.000000          0.000000         0.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = LogisticRegression(\n",
    "     max_iter=10000\n",
    "    ,fit_intercept=True # always fit an intercept term\n",
    "    ,n_jobs=-1 # use all processors\n",
    ")\n",
    "pipe = Pipeline(steps=[('logistic', logistic)])\n",
    "# Parameters of pipelines can be set using __ separated parameter names:\n",
    "param_grid = {\n",
    "    'logistic__C': np.logspace(-4, 4, 10),\n",
    "    #'logistic__class_weight':[None, 'balanced'],\n",
    "    'logistic__penalty':['l1', 'l2','elasticnet', 'none'],\n",
    "    #'logistic__multi_class':['auto', 'ovr', 'multinomial'],\n",
    "    #'logistic__dual':[True, False],\n",
    "    #'logistic__solver':['lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=-1,error_score=0.0,scoring='accuracy')\n",
    "search.fit(X_train, y_train.values.ravel())\n",
    "print(\"Best parameter (Accuracy score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40 entries, 0 to 39\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean_fit_time            40 non-null     float64\n",
      " 1   std_fit_time             40 non-null     float64\n",
      " 2   mean_score_time          40 non-null     float64\n",
      " 3   std_score_time           40 non-null     float64\n",
      " 4   param_logistic__C        40 non-null     object \n",
      " 5   param_logistic__penalty  40 non-null     object \n",
      " 6   params                   40 non-null     object \n",
      " 7   split0_test_score        40 non-null     float64\n",
      " 8   split1_test_score        40 non-null     float64\n",
      " 9   split2_test_score        40 non-null     float64\n",
      " 10  mean_test_score          40 non-null     float64\n",
      " 11  std_test_score           40 non-null     float64\n",
      " 12  rank_test_score          40 non-null     int32  \n",
      " 13  split0_train_score       40 non-null     float64\n",
      " 14  split1_train_score       40 non-null     float64\n",
      " 15  split2_train_score       40 non-null     float64\n",
      " 16  mean_train_score         40 non-null     float64\n",
      " 17  std_train_score          40 non-null     float64\n",
      "dtypes: float64(14), int32(1), object(3)\n",
      "memory usage: 5.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20 entries, 0 to 37\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean_fit_time            20 non-null     float64\n",
      " 1   std_fit_time             20 non-null     float64\n",
      " 2   mean_score_time          20 non-null     float64\n",
      " 3   std_score_time           20 non-null     float64\n",
      " 4   param_logistic__C        20 non-null     object \n",
      " 5   param_logistic__penalty  20 non-null     object \n",
      " 6   params                   20 non-null     object \n",
      " 7   split0_test_score        20 non-null     float64\n",
      " 8   split1_test_score        20 non-null     float64\n",
      " 9   split2_test_score        20 non-null     float64\n",
      " 10  mean_test_score          20 non-null     float64\n",
      " 11  std_test_score           20 non-null     float64\n",
      " 12  rank_test_score          20 non-null     int32  \n",
      " 13  split0_train_score       20 non-null     float64\n",
      " 14  split1_train_score       20 non-null     float64\n",
      " 15  split2_train_score       20 non-null     float64\n",
      " 16  mean_train_score         20 non-null     float64\n",
      " 17  std_train_score          20 non-null     float64\n",
      "dtypes: float64(14), int32(1), object(3)\n",
      "memory usage: 2.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    20.000000\n",
       "mean      0.789956\n",
       "std       0.077457\n",
       "min       0.465997\n",
       "25%       0.808673\n",
       "50%       0.812827\n",
       "75%       0.812998\n",
       "max       0.812998\n",
       "Name: mean_test_score, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.info()\n",
    "results.mean_test_score.describe()\n",
    "\n",
    "results2 = results[results.mean_test_score > 0].copy()\n",
    "results2.info()\n",
    "results2.mean_test_score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sns.set(style='darkgrid')\n",
    "p1 = sns.lineplot(x=\"param_logistic__C\", y=\"mean_test_score\", data=results, ci=None)\n",
    "p2 = sns.boxplot(x=\"param_logistic__penalty\", y=\"mean_test_score\", data=results)\n",
    "print(p1)\n",
    "print(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-04, 4.64158883e-02, 2.15443469e+01, 1.00000000e+04])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-4, 4, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ModelAdvantages\"></a>\n",
    "# Model Advantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[10] Discuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency? Explain in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"InterpretFeatureImportance\"></a>\n",
    "# Interpret Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[30] Use the weights from logistic regression to interpret the importance of different features for the classification task. Explain your interpretation in detail. Why do you think some variables are more important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"InterpretSupportVectors\"></a>\n",
    "# Interpret Support Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[10] Look at the chosen support vectors for the classification task. Do these provide any insight into the data? Explain. If you used stochastic gradient descent (and therefore did not explicitly solve for support vectors), try subsampling your data to train the SVC model then analyze the support vectors from the subsampled dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Conclusion\"></a>\n",
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
